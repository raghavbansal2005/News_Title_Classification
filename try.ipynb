{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./News_Category_Dataset_v2.json\", lines=True)\n",
    "df.to_json('news_data.json',orient = 'records')\n",
    "df = pd.read_json(\"./news_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = len(df)\n",
    "shuffled_df = df.sample(frac=1)\n",
    "lens = [int(0.8*len(df)),int(0.9*len(df)),(len(df)-1)]\n",
    "train_data = shuffled_df[:lens[0]]\n",
    "val_data = shuffled_df[(lens[0]+1):lens[1]]\n",
    "test_data = shuffled_df[(lens[1]+1):lens[2]]\n",
    "\n",
    "train_data = shuffled_df[:20600]\n",
    "val_data = shuffled_df[20601:22700]\n",
    "test_data = shuffled_df[22701:24701]\n",
    "\n",
    "\n",
    "\n",
    "train_data.to_json(\"./splits/train.json\",orient = 'records')\n",
    "val_data.to_json(\"./splits/val.json\",orient = 'records')\n",
    "test_data.to_json(\"./splits/test.json\",orient = 'records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in shuffled_df.iterrows():\n",
    "    shuffled_df.at[index,\"headline\"] = row[\"headline\"] + \" \" + row[\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffled_df[:lens[0]]\n",
    "val_data = shuffled_df[(lens[0]+1):lens[1]]\n",
    "test_data = shuffled_df[(lens[1]+1):lens[2]]\n",
    "\n",
    "train_data = shuffled_df[:20600]\n",
    "val_data = shuffled_df[20601:22700]\n",
    "test_data = shuffled_df[22701:24701]\n",
    "\n",
    "\n",
    "\n",
    "train_data.to_json(\"./splits/train.json\",orient = 'records')\n",
    "val_data.to_json(\"./splits/val.json\",orient = 'records')\n",
    "test_data.to_json(\"./splits/test.json\",orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_data[\"headline\"]:\n",
    "    if x is None:\n",
    "        print(\"sfsdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200853\n"
     ]
    }
   ],
   "source": [
    "list_of_cat = df[\"category\"].to_list()\n",
    "print(len(list_of_cat))\n",
    "set_of_cat = set()\n",
    "for cat in list_of_cat:\n",
    "    set_of_cat.add(cat)\n",
    "\n",
    "category_to_id_map = dict()\n",
    "\n",
    "i = 0\n",
    "for cat in set_of_cat:\n",
    "    category_to_id_map[cat] = i\n",
    "    i = i + 1\n",
    "\n",
    "with open(\"./category_to_id.json\", 'w') as fp:\n",
    "    json.dump(category_to_id_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\", lowercase=True)\n",
    "\n",
    "raw_text = [\"Hello, what is your name?\", \"This is very cool\", \"I do not like you\"]\n",
    "\n",
    "batch = tokenizer.encode_batch(raw_text, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_frequencies = {}\n",
    "for key in category_to_id_map:\n",
    "    classes_frequencies[key] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EDUCATION': 1004, 'CULTURE & ARTS': 1030, 'LATINO VOICES': 1129, 'COLLEGE': 1144, 'ENVIRONMENT': 1323, 'ARTS & CULTURE': 1339, 'GOOD NEWS': 1398, 'FIFTY': 1401, 'ARTS': 1509, 'MONEY': 1707, 'TECH': 2082, 'TASTE': 2096, 'WORLD NEWS': 2177, 'SCIENCE': 2178, 'STYLE': 2254, 'RELIGION': 2556, 'WORLDPOST': 2579, 'GREEN': 2622, 'WEIRD NEWS': 2670, 'MEDIA': 2815, 'CRIME': 3405, 'DIVORCE': 3426, 'IMPACT': 3459, 'WOMEN': 3490, 'WEDDINGS': 3651, 'THE WORLDPOST': 3664, 'PARENTS': 3955, 'HOME & LIVING': 4195, 'BLACK VOICES': 4528, 'SPORTS': 4884, 'COMEDY': 5175, 'BUSINESS': 5937, 'FOOD & DRINK': 6226, 'QUEER VOICES': 6314, 'HEALTHY LIVING': 6694, 'PARENTING': 8677, 'STYLE & BEAUTY': 9649, 'TRAVEL': 9887, 'ENTERTAINMENT': 16058, 'WELLNESS': 17827, 'POLITICS': 32739}\n"
     ]
    }
   ],
   "source": [
    "for index, row in shuffled_df.iterrows():\n",
    "    classes_frequencies[row[\"category\"]] += 1\n",
    "\n",
    "print(dict(sorted(classes_frequencies.items(), key=lambda item: item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_down_df = shuffled_df.loc[df['category'].isin([\"POLITICS\", \"WELLNESS\", \"ENTERTAINMENT\", \"TRAVEL\", \"STYLE & BEAUTY\", \"PARENTING\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for index, row in scaled_down_df.iterrows():\n",
    "    tokenized_sentence =  str(row[\"headline\"]).split(\" \")\n",
    "\n",
    "    filtered_sentence = [w for w in tokenized_sentence if not w.lower() in stop_words]\n",
    "  \n",
    "    filtered_sentence_list = []\n",
    "\n",
    "    for w in filtered_sentence:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence_list.append(w)\n",
    "    \n",
    "    filtered_sentence = \"\"\n",
    "    for w in filtered_sentence_list:\n",
    "        filtered_sentence = filtered_sentence + w + \" \";\n",
    "\n",
    "    filtered_sentence = filtered_sentence[:-1]\n",
    "\n",
    "    scaled_down_df.at[index, \"headline\"] = filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dianne Feinstein Officially Has A Primary Challenger California Democratic state Senate President Kevin de Le√≥n running unseat Democratic incumbent.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_down_df.iloc[0][\"headline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94837"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_down_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_scaled_down_df = scaled_down_df.sample(frac=1)\n",
    "\n",
    "train_data = shuffled_scaled_down_df[:20600]\n",
    "val_data = shuffled_scaled_down_df[20601:22700]\n",
    "test_data = shuffled_scaled_down_df[22701:24701]\n",
    "\n",
    "\n",
    "\n",
    "train_data.to_json(\"./splits/train.json\",orient = 'records')\n",
    "val_data.to_json(\"./splits/val.json\",orient = 'records')\n",
    "test_data.to_json(\"./splits/test.json\",orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_id_map = {'PARENTING': 0, 'STYLE & BEAUTY': 1, 'TRAVEL': 2, 'ENTERTAINMENT': 3, 'WELLNESS': 4, 'POLITICS': 5}\n",
    "\n",
    "with open(\"./category_to_id.json\", 'w') as fp:\n",
    "    json.dump(category_to_id_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].pad(8)\n",
    "batch[0].ids\n",
    "batch[0].attention_mask\n",
    "len(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bddfc6c967618de3b601b0077a158d4f780614c80ac4c9d0c2f643343eb0a807"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
